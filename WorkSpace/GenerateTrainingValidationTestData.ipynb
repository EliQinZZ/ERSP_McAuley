{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file splits the run/bike data into training, validation and test dataset, and generates corresponding files\n",
    "from random import shuffle\n",
    "import gzip\n",
    "\n",
    "sportlist = [\"run_cleaned.json.gz\",\"bike_cleaned.json.gz\",\"bike (transport)_cleaned.json.gz\"]\n",
    "\n",
    "# Set the ratio among sizes of training/validation/test dataset\n",
    "train_percent = 0.42\n",
    "validation_percent = 0.18\n",
    "test_percent = 0.40\n",
    "\n",
    "# Put the workout data of run.json/biking.json into workout_list\n",
    "for sportfile in sportlist:\n",
    "    workout_list = []\n",
    "    total_workout = 0\n",
    "    with gzip.open(\"../data/\"+sportfile,'r') as file:\n",
    "        for workout in file:\n",
    "            total_workout = total_workout + 1\n",
    "            workout_list.append(workout)\n",
    "    \n",
    "    print(\"Finished reading \" + sportfile + \"\\n\")\n",
    "    shuffle(workout_list)\n",
    "    print(\"Finished shuffling \" + sportfile + \"\\n\")\n",
    "    \n",
    "    # Calculate sizes of training/validation/test dataset\n",
    "    train_size = int(train_percent * total_workout)\n",
    "    validation_size = int(validation_percent * total_workout)\n",
    "    test_size = total_workout - train_size - validation_size\n",
    "    \n",
    "    print(\"Size of total workout for \" + sportfile + \" is %d \\n\"%total_workout)\n",
    "    print(\"Size of training set for \" + sportfile + \" is %d \\n\"%train_size)\n",
    "    print(\"Size of validation set for \" + sportfile + \" is %d \\n\"%validation_size)\n",
    "    print(\"Size of test set for \" + sportfile + \" is %d \\n\"%test_size)\n",
    "    \n",
    "    # Split the workout data according to the calculated sizes above\n",
    "    # Note: slicing \":\" is left-inclusive and right-exclusive\n",
    "    train_list = workout_list[:train_size]\n",
    "    validation_list = workout_list[train_size : train_size + validation_size]\n",
    "    test_list = workout_list[train_size + validation_size:]\n",
    "    \n",
    "    # Write into separate files\n",
    "    with gzip.open(\"training_set_%s\"%sportfile, 'wb') as file1:\n",
    "        for workout in train_list:\n",
    "            file1.write(bytes(str(workout)+'\\n','ascii'))\n",
    "    print(\"Finished writing training set for \" + sportfile + \"\\n\")\n",
    "    \n",
    "    with gzip.open(\"validation_set_%s\"%sportfile, 'wb') as file2:\n",
    "        for workout in validation_list:\n",
    "            file2.write(bytes(str(workout)+'\\n','ascii'))\n",
    "    print(\"Finished writing validation set for \" + sportfile + \"\\n\")\n",
    "\n",
    "    with gzip.open(\"test_set_%s\"%sportfile, 'wb') as file3:\n",
    "        for workout in test_list:\n",
    "            file3.write(bytes(str(workout)+'\\n','ascii'))\n",
    "    print(\"Finished writing test set for \" + sportfile + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
