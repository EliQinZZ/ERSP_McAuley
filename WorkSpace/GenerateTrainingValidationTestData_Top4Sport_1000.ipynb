{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading \n",
      "\n",
      "Finished shuffling \n",
      "\n",
      "Size of total workout is 1000 \n",
      "\n",
      "Size of training set is 420 \n",
      "\n",
      "Size of validation set is 180 \n",
      "\n",
      "Size of test set is 400 \n",
      "\n",
      "Finished writing training set\n",
      "\n",
      "Finished writing validation set\n",
      "\n",
      "Finished writing test set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This file splits the run/bike data into training, validation and test dataset, and generates corresponding files\n",
    "from random import shuffle\n",
    "import gzip\n",
    "\n",
    "sportlist = [\"run_cleaned.json.gz\",\"bike_cleaned.json.gz\",\"bike (transport)_cleaned.json.gz\",\"mountain bike_cleaned.json.gz\"]\n",
    "\n",
    "# Set the ratio among sizes of training/validation/test dataset\n",
    "train_percent = 0.42\n",
    "validation_percent = 0.18\n",
    "test_percent = 0.40\n",
    "\n",
    "workout_list = []\n",
    "total_workout = 0\n",
    "# Put the workout data of run.json/biking.json into workout_list\n",
    "for sportfile in sportlist:\n",
    "    with gzip.open(\"../data/\"+sportfile,'r') as file:\n",
    "        count = 0\n",
    "        for workout in file:\n",
    "            if(count >= 1000):\n",
    "                break\n",
    "            workout_list.append(workout)\n",
    "            count += 1\n",
    "            total_workout += 1\n",
    "    \n",
    "print(\"Finished reading \\n\")\n",
    "shuffle(workout_list)\n",
    "print(\"Finished shuffling \\n\")\n",
    "    \n",
    "# Calculate sizes of training/validation/test dataset\n",
    "train_size = int(train_percent * total_workout)\n",
    "validation_size = int(validation_percent * total_workout)\n",
    "test_size = total_workout - train_size - validation_size\n",
    "    \n",
    "print(\"Size of total workout is %d \\n\"%total_workout)\n",
    "print(\"Size of training set is %d \\n\"%train_size)\n",
    "print(\"Size of validation set is %d \\n\"%validation_size)\n",
    "print(\"Size of test set is %d \\n\"%test_size)\n",
    "    \n",
    "# Split the workout data according to the calculated sizes above\n",
    "# Note: slicing \":\" is left-inclusive and right-exclusive\n",
    "train_list = workout_list[:train_size]\n",
    "validation_list = workout_list[train_size : train_size + validation_size]\n",
    "test_list = workout_list[train_size + validation_size:]\n",
    "    \n",
    "# Write into separate files\n",
    "with gzip.open(\"training_set_top4_1000.json.gz\", 'wb') as file1:\n",
    "    for workout in train_list:\n",
    "        file1.write(workout)\n",
    "print(\"Finished writing training set\\n\")\n",
    "    \n",
    "with gzip.open(\"validation_set_top4_1000.json.gz\", 'wb') as file2:\n",
    "    for workout in validation_list:\n",
    "        file2.write(workout)\n",
    "print(\"Finished writing validation set\\n\")\n",
    "\n",
    "with gzip.open(\"test_set_top4_1000.json.gz\", 'wb') as file3:\n",
    "    for workout in test_list:\n",
    "        file3.write(workout)\n",
    "print(\"Finished writing test set\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
